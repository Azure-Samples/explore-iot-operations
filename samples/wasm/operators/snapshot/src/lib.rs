// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.

// Generated by `wit_bindgen::generate` expansion.
#![allow(clippy::missing_safety_doc)]

mod map_snapshot {
    use std::sync::LazyLock;

    use tinykube_wasm_sdk::logger::{self, Level};
    use tinykube_wasm_sdk::macros::map_operator;
    use tinykube_wasm_sdk::metrics::{self, CounterValue, Label};

    use crate::{Measurement, MeasurementObject};

    const MODEL: &[u8] = include_bytes!("fixture/models/mobilenet.onnx");
    const MODEL_OUTPUT_NAME: &str = "mobilenetv20_output_flatten0_reshape0";
    const LABEL_MAP: &[u8] = include_bytes!("fixture/labels/synset.txt");

    // wasmtime-wasi-nn example requirements
    // from https://github.com/bytecodealliance/wasmtime/blob/main/crates/wasi-nn/examples/classification-component-onnx/src/main.rs
    use core::panic;
    use ndarray::{Array, Dim};
    use std::io::BufRead;

    use wasi_nn::{
        graph::{load, ExecutionTarget, Graph, GraphEncoding, GraphExecutionContext},
        tensor::{Tensor, TensorData, TensorDimensions, TensorType},
    };

    static mut CONTEXT: LazyLock<GraphExecutionContext> = LazyLock::new(|| {
        let graph = load(&[MODEL.to_vec()], GraphEncoding::Onnx, ExecutionTarget::Cpu).unwrap();
        Graph::init_execution_context(&graph).unwrap()
    });

    #[map_operator]
    fn object_detection(message: DataModel) -> DataModel {
        let labels = vec![Label {
            key: "module".to_owned(),
            value: "module-snapshot/map".to_owned(),
        }];
        let _ = metrics::add_to_counter("requests", CounterValue::U64(1), Some(&labels));

        // Obtain Snapshot instance
        let DataModel::Snapshot(snapshot) = message else {
            panic!("Unexpected input type");
        };

        // Extract payload from message to process
        let payload = match &snapshot.frame {
            BufferOrBytes::Buffer(buffer) => buffer.read(),
            BufferOrBytes::Bytes(bytes) => bytes.clone(),
        };

        // Initialize result as Message Format
        let mut result = Snapshot {
            timestamp: snapshot.timestamp,
            format: snapshot.format,
            width: snapshot.width,
            height: snapshot.height,
            frame: snapshot.frame,
        };

        // Load the ONNX model - SqueezeNet 1.1-7
        // Full details: https://github.com/onnx/models/tree/main/vision/classification/squeezenet
        // let graph = load(&[MODEL.to_vec()], GraphEncoding::Onnx, ExecutionTarget::Cpu).unwrap();
        // let exec_context = Graph::init_execution_context(&graph).unwrap();
        let exec_context = &raw mut CONTEXT;

        // Load SquezeNet 1000 labels used for classification
        let class_labels: Vec<String> = LABEL_MAP.lines().map(|line| line.unwrap()).collect();

        // Prepare WASI-NN tensor - Tensor data is always a bytes vector
        let dimensions: TensorDimensions = vec![1, 3, 224, 224];
        let data: TensorData = image_to_tensor(&payload);
        let tensor = Tensor::new(&dimensions, TensorType::Fp32, &data);

        unsafe {
            match (*exec_context).set_input("data", tensor) {
                Ok(()) => {}
                Err(e) => {
                    logger::log(
                        Level::Error,
                        "module-snapshot/map",
                        &format!("Error setting input tensor: {e:?}"),
                    );
                    panic!("Error setting input tensor: {:?}", e);
                }
            }

            // Execute the inferencing
            match (*exec_context).compute() {
                Ok(()) => {}
                Err(e) => {
                    logger::log(
                        Level::Error,
                        "module-snapshot/map",
                        &format!("Error executing graph inference: {e:?}"),
                    );
                    panic!("Error executing graph inference: {e:?}");
                }
            }

            // Get the inferencing result (bytes) and convert it to f32
            let output_data = (*exec_context)
                .get_output(MODEL_OUTPUT_NAME)
                .unwrap()
                .data();
            let output_f32 = bytes_to_f32_vec(&output_data);

            let output_shape = [1, 1000, 1, 1];
            let output_tensor = Array::from_shape_vec(output_shape, output_f32).unwrap();

            // Post-Processing requirement: compute softmax to inferencing output
            let exp_output = output_tensor.mapv(f32::exp);
            let sum_exp_output = exp_output.sum_axis(ndarray::Axis(1));
            let softmax_output = exp_output / &sum_exp_output;

            let mut sorted = softmax_output
                .axis_iter(ndarray::Axis(1))
                .enumerate()
                .map(|(i, v)| (i, v[Dim([0, 0, 0])]))
                .collect::<Vec<(_, _)>>();
            sorted.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap());

            for (index, probability) in sorted.iter().take(1) {
                let mut parts = class_labels[*index].splitn(2, ' '); // split at the first space
                parts.next(); // skip the first part
                let remaining_part = parts.next().unwrap_or("");

                logger::log(
                    Level::Info,
                    "module-snapshot/map",
                    &format!(
                        "Object detection result: {} - Probability: {}",
                        class_labels[*index], probability
                    ),
                );

                let result_payload = serde_json::to_vec(&Measurement::Object(MeasurementObject {
                    result: remaining_part.to_string(),
                }))
                .unwrap();
                result.frame = BufferOrBytes::Bytes(result_payload);
            }
        }

        DataModel::Snapshot(result)
    }

    pub fn bytes_to_f32_vec(data: &[u8]) -> Vec<f32> {
        let chunks: Vec<&[u8]> = data.chunks(4).collect();
        let v: Vec<f32> = chunks
            .into_iter()
            .map(|c| f32::from_le_bytes(c.try_into().unwrap()))
            .collect();

        v.into_iter().collect()
    }

    // Take the image located at 'path', open it, resize it to height x width, and then converts
    // the pixel precision to FP32. The resulting BGR pixel vector is then returned.
    fn image_to_tensor(data: &Vec<u8>) -> Vec<u8> {
        // Create an array to hold the f32 value of those pixels
        let bytes_required = (*data).len() * 4;
        let mut u8_f32_arr: Vec<u8> = vec![0; bytes_required];

        // Normalizing values for the model
        let mean = [0.485, 0.456, 0.406];
        let std = [0.229, 0.224, 0.225];

        // Read the number as a f32 and break it into u8 bytes
        for i in 0..(*data).len() {
            let u8_f32: f32 = f32::from((*data)[i]);
            let rgb_iter = i % 3;

            // Normalize the pixel
            let norm_u8_f32: f32 = (u8_f32 / 255.0 - mean[rgb_iter]) / std[rgb_iter];

            // Convert it to u8 bytes and write it with new shape
            let u8_bytes = norm_u8_f32.to_ne_bytes();
            for j in 0..4 {
                u8_f32_arr[((*data).len() * 4 * rgb_iter / 3) + (i / 3) * 4 + j] = u8_bytes[j];
            }
        }

        u8_f32_arr
    }
}

mod branch_snapshot {
    use std::sync::OnceLock;
    use tinykube_wasm_sdk::logger::{self, Level};
    use tinykube_wasm_sdk::macros::branch_operator;
    use tinykube_wasm_sdk::metrics::{self, CounterValue, Label};

    static SNAPSHOT_MQTT_TOPIC: OnceLock<Vec<u8>> = OnceLock::new();

    fn check_snapshot_init(configuration: ModuleConfiguration) -> bool {
        logger::log(
            Level::Info,
            "module-snapshot/branch",
            &format!("Initialization function invoked"),
        );

        if let Some(topic_name) = configuration
            .properties
            .iter()
            .find(|(key, _value)| key == "snapshot_topic") // or whatever it is
            .map(|(_key, value)| value.clone())
        {
            if let Err(_) = SNAPSHOT_MQTT_TOPIC.set(topic_name.into_bytes()) {
                logger::log(
                    Level::Info,
                    "module-snapshot/branch",
                    &format!("Failed to set snapshot topic!"),
                );
            }
        }

        true
    }

    #[branch_operator(init = "check_snapshot_init")]
    fn check_snapshot(_timestamp: HybridLogicalClock, input: DataModel) -> bool {
        let labels = vec![Label {
            key: "module".to_owned(),
            value: "module-snapshot/branch".to_owned(),
        }];

        logger::log(
            Level::Info,
            "module-snapshot/branch",
            &format!("entered check_snapshot function"),
        );

        let _ = metrics::add_to_counter("requests", CounterValue::U64(1), Some(&labels));

        let result = match input {
            DataModel::Message(message) => {
                let mut res = false;
                if let Some(topic) = SNAPSHOT_MQTT_TOPIC.get() {
                    if message.topic.read() == *topic {
                        res = true;
                    }
                }
                res
            }
            DataModel::Snapshot(_frame) => true,
            DataModel::BufferOrBytes(_) => panic!("Unexpected input type"),
        };
        logger::log(
            Level::Info,
            "module-snapshot/branch",
            &format!("check_snapshot result: {}", result),
        );
        result
    }
}

mod accumulate_snapshot {
    use tinykube_wasm_sdk::logger::{self, Level};
    use tinykube_wasm_sdk::macros::accumulate_operator;
    use tinykube_wasm_sdk::metrics::{self, CounterValue, Label};

    use crate::{Measurement, MeasurementObject};

    #[accumulate_operator]
    fn accumulate_detected_objects(staged: DataModel, inputs: Vec<DataModel>) -> DataModel {
        let labels = vec![Label {
            key: "module".to_owned(),
            value: "module-snapshot/accumulate".to_owned(),
        }];
        let _ = metrics::add_to_counter("requests", CounterValue::U64(1), Some(&labels));

        let DataModel::Message(mut result) = staged else {
            panic!("Unexpected input type");
        };

        // Extract payload from message to process
        let staged_payload = match &result.payload {
            BufferOrBytes::Buffer(buffer) => buffer.read(),
            BufferOrBytes::Bytes(bytes) => bytes.clone(),
        };

        let mut objects: Vec<String> = Vec::new();

        if staged_payload.len() > 0 {
            let measurement: Measurement = serde_json::from_slice(&staged_payload).unwrap();
            match measurement {
                Measurement::Object(measurement) => {
                    // Directly push the object into the list
                    objects.push(measurement.result);
                }
                _ => {},
            }
        }

        // Process each new inputs
        for input in inputs {
            let (_ts, _width, _height, payload) = match input {
                DataModel::Snapshot(temp) => {
                    // Extract payload from message to process
                    (temp.timestamp.timestamp, temp.width, temp.height, match &temp.frame {
                        BufferOrBytes::Buffer(buffer) => buffer.read(),
                        BufferOrBytes::Bytes(bytes) => bytes.clone(),
                    })
                }
                _ => panic!("Unexpected input type"),
            };

            let measurement: Measurement = serde_json::from_slice(&payload).unwrap();
            match measurement {
                Measurement::Object(measurement) => {
                    // Check if the object is already in the list
                    if !objects.contains(&measurement.result) {
                        objects.push(measurement.result);
                    }
                }
                _ => panic!("Unexpected input type"),
            }
        }

        let result_payload = serde_json::to_vec(&Measurement::Object(MeasurementObject {
            result: objects.join("; "),
        })).unwrap();

        logger::log(
            Level::Info,
            "module-snapshot/accumulate",
            &result_payload.iter().map(|b| *b as char).collect::<String>(),
        );

        result.payload = BufferOrBytes::Bytes(result_payload);
        DataModel::Message(result)
    }
}


#[derive(Debug, PartialEq, serde::Deserialize, serde::Serialize)]
pub enum Measurement {
    #[serde(rename = "temperature")]
    Temperature(MeasurementTemperature),

    #[serde(rename = "humidity")]
    Humidity(MeasurementHumidity),

    #[serde(rename = "object")]
    Object(MeasurementObject),

    #[serde(rename = "sensor_data")]
    SensorData(MeasurementSensorData),
}

#[derive(Debug, PartialEq, serde::Deserialize, serde::Serialize)]
pub struct MeasurementTemperature {
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub value: Option<f64>,
    #[serde(default)]
    pub count: u64,
    #[serde(default)]
    pub max: f64,
    #[serde(default)]
    pub min: f64,
    #[serde(default)]
    pub average: f64,
    #[serde(default)]
    pub last: f64,
    pub unit: MeasurementTemperatureUnit,
    #[serde(default)]
    pub overtemp: bool,
}

#[derive(Clone, Copy, Debug, Eq, PartialEq, serde::Deserialize, serde::Serialize)]
pub enum MeasurementTemperatureUnit {
    #[serde(rename = "C")]
    Celsius,

    #[serde(rename = "F")]
    Fahrenheit,
}

#[derive(Debug, PartialEq, serde::Deserialize, serde::Serialize)]
pub struct MeasurementHumidity {
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub value: Option<f64>,
    #[serde(default)]
    pub count: u64,
    #[serde(default)]
    pub max: f64,
    #[serde(default)]
    pub min: f64,
    #[serde(default)]
    pub average: f64,
    #[serde(default)]
    pub last: f64,
}

#[derive(Debug, PartialEq, serde::Deserialize, serde::Serialize)]
pub struct MeasurementObject {
    pub result: String,
}

#[derive(Debug, PartialEq, serde::Deserialize, serde::Serialize)]
pub struct MeasurementSensorData {
    #[serde(default)]
    pub temperature: Vec<MeasurementTemperature>,

    #[serde(default)]
    pub humidity: Vec<MeasurementHumidity>,

    #[serde(default)]
    pub object: Vec<MeasurementObject>,
}

impl Default for MeasurementSensorData {
    fn default() -> Self {
        Self::new()
    }
}

impl MeasurementSensorData {
    pub fn new() -> Self {
        Self {
            temperature: Vec::new(),
            humidity: Vec::new(),
            object: Vec::new(),
        }
    }

    pub fn temperature(&mut self) -> &mut [MeasurementTemperature] {
        &mut self.temperature
    }

    pub fn humidity(&mut self) -> &mut [MeasurementHumidity] {
        &mut self.humidity
    }

    pub fn object(&mut self) -> &mut [MeasurementObject] {
        &mut self.object
    }
}
